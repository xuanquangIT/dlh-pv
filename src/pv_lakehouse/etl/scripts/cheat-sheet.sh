#!/bin/bash
# Quick Cheat Sheet - Copy & Paste Commands

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘          PV Lakehouse - Quick Command Reference             â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

echo "ğŸ“¦ BRONZE LAYER - Data Ingestion"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facilities.py --mode incremental"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_timeseries.py --mode incremental"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_weather.py --mode incremental"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_air_quality.py --mode incremental"
echo ""

echo "âœ¨ SILVER LAYER - Data Transformation"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py facility_master --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_energy --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_weather --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_air_quality --mode full"
echo ""

echo "ğŸ† GOLD LAYER - Analytics & Data Mart"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "# Dimension Tables (Load these first)"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_date --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_time --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_facility --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_weather_condition --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_air_quality_category --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_equipment_status --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_performance_issue --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py dim_model_version --mode full"
echo ""
echo "# Fact Tables (Load after dimensions)"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py fact_kpi_performance --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py fact_weather_impact --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py fact_air_quality_impact --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py fact_solar_forecast --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/gold/run_loader.py fact_root_cause_analysis --mode full"
echo ""

echo "ğŸ”„ BACKFILL - Load Historical Data"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "# Bronze Backfill (NOTE: Timeseries uses UTC time, auto-converts to Brisbane timezone)"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_timeseries.py --mode backfill --date-start 2025-10-01T00:00:00 --date-end 2025-10-22T23:59:59"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_weather.py --mode backfill --start 2025-10-01 --end 2025-10-22"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/bronze/load_facility_air_quality.py --mode backfill --start 2025-10-01 --end 2025-10-22"
echo ""
echo "# Silver Transform (Full mode processes all Bronze data)"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_energy --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_weather --mode full"
echo "bash src/pv_lakehouse/etl/scripts/spark-submit.sh src/pv_lakehouse/etl/silver/cli.py hourly_air_quality --mode full"
echo ""

echo "ğŸ—‘ï¸  DELETE DATA - Cleanup"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "# Bronze Layer"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM bronze.raw_facility_timeseries;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM bronze.raw_facility_weather;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM bronze.raw_facility_air_quality;\""
echo ""
echo "# Silver Layer"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM silver.clean_hourly_energy;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM silver.clean_hourly_weather;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM silver.clean_hourly_air_quality;\""
echo ""
echo "# Gold Layer - Dimensions"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM gold.dim_date;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM gold.dim_facility;\""
echo ""
echo "# Gold Layer - Facts"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM gold.fact_kpi_performance;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM gold.fact_weather_impact;\""
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"DELETE FROM gold.fact_air_quality_impact;\""
echo ""

echo "ğŸ“Š QUERY DATA - Check Results"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "# Bronze - Count rows"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \"SELECT COUNT(*) FROM bronze.raw_facility_timeseries;\""
echo ""
echo "# Bronze - Check date ranges"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \\"
echo "  \"SELECT MIN(interval_ts), MAX(interval_ts), COUNT(*) FROM bronze.raw_facility_timeseries;\""
echo ""
echo "# Silver - Check hourly data"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \\"
echo "  \"SELECT facility_code, COUNT(*) as row_count FROM silver.clean_hourly_energy GROUP BY facility_code;\""
echo ""
echo "# Gold - Dimensions summary"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \\"
echo "  \"SELECT 'dim_date' as table_name, COUNT(*) as row_count FROM gold.dim_date \\"
echo "   UNION ALL SELECT 'dim_time', COUNT(*) FROM gold.dim_time \\"
echo "   UNION ALL SELECT 'dim_facility', COUNT(*) FROM gold.dim_facility \\"
echo "   UNION ALL SELECT 'dim_weather_condition', COUNT(*) FROM gold.dim_weather_condition;\""
echo ""
echo "# Gold - Facts summary"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \\"
echo "  \"SELECT 'fact_kpi_performance' as table_name, COUNT(*) as row_count FROM gold.fact_kpi_performance \\"
echo "   UNION ALL SELECT 'fact_weather_impact', COUNT(*) FROM gold.fact_weather_impact \\"
echo "   UNION ALL SELECT 'fact_air_quality_impact', COUNT(*) FROM gold.fact_air_quality_impact;\""
echo ""
echo "# Gold - Sample KPI data"
echo "docker compose -f docker/docker-compose.yml exec trino trino --catalog iceberg --schema lh --execute \\"
echo "  \"SELECT facility_key, date_key, actual_energy_mwh, performance_ratio_pct \\"
echo "   FROM gold.fact_kpi_performance ORDER BY date_key DESC LIMIT 10;\""
echo ""

echo "ğŸ³ DOCKER - Service Management"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "docker compose -f docker/docker-compose.yml up -d"
echo "docker compose -f docker/docker-compose.yml ps"
echo "docker compose -f docker/docker-compose.yml logs -f spark-master"
echo "docker compose -f docker/docker-compose.yml exec spark-master bash"
echo ""

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âš¡ IMPORTANT NOTES"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "TIMEZONE:"
echo "  â€¢ Timeseries: Input UTC datetime (auto-converts to Brisbane UTC+10 for API)"
echo "  â€¢ Weather/Air Quality: Input date only (API uses UTC timezone)"
echo "  â€¢ Example: --date-start 2025-10-01T00:00:00 â†’ Data starts exactly at 2025-10-01 00:00 UTC"
echo ""
echo "GOLD LAYER DEPENDENCIES:"
echo "  â€¢ Dimensions MUST be loaded before Facts"
echo "  â€¢ Facts depend on: dim_facility, dim_time, dim_date, dim_weather_condition, etc."
echo "  â€¢ Order: Bronze â†’ Silver â†’ Gold Dimensions â†’ Gold Facts"
echo ""
echo "PERFORMANCE OPTIMIZATIONS (Gold Layer):"
echo "  â€¢ âœ… Broadcast joins for small dimensions (5-10x faster)"
echo "  â€¢ âœ… Shuffle partitions optimized: 8 (vs 200 default)"
echo "  â€¢ âœ… Auto-broadcast threshold: 10MB"
echo "  â€¢ Expected runtime: ~40-60 seconds for full Gold load"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ’¡ QUICK TIPS"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  â€¢ All ETL scripts: src/pv_lakehouse/etl/{bronze,silver,gold}/"
echo "  â€¢ Spark submit wrapper: src/pv_lakehouse/etl/scripts/spark-submit.sh"
echo "  â€¢ Spark configs: src/pv_lakehouse/etl/utils/spark_utils.py"
echo "  â€¢ Documentation: doc/optimization/gold-layer-optimization.md"
echo "  â€¢ Run all layers: bash src/pv_lakehouse/etl/scripts/spark-submit.sh <script> --mode full"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
