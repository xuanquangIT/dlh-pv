// Trino ODBC Configuration Example for Power BI

// =============================================================================
// WINDOWS - ODBC Data Source Name (DSN) Configuration
// =============================================================================

[Trino_Lakehouse]
Driver=Trino ODBC Driver
Description=Trino Connection for PV Lakehouse Gold Layer
Server=localhost
Port=8081
Catalog=iceberg
Schema=gold
User=trino
AuthType=NONE
SSLMode=off
LogLevel=0

// Connection string version:
// Driver={Trino ODBC Driver};Server=localhost;Port=8081;Catalog=iceberg;Schema=gold;User=trino;AuthType=NONE

// =============================================================================
// REMOTE SERVER - ODBC Configuration
// =============================================================================

[Trino_Lakehouse_Remote]
Driver=Trino ODBC Driver
Description=Trino Connection for PV Lakehouse (Remote)
Server=192.168.1.100      // REPLACE WITH YOUR SERVER IP
Port=8081
Catalog=iceberg
Schema=gold
User=trino
AuthType=NONE
SSLMode=off

// Connection string version:
// Driver={Trino ODBC Driver};Server=192.168.1.100;Port=8081;Catalog=iceberg;Schema=gold;User=trino;AuthType=NONE

// =============================================================================
// MAC/LINUX - ODBC Configuration (in ~/.odbc.ini)
// =============================================================================

[Trino_Lakehouse]
Driver=Trino ODBC Driver
Description=Trino Connection for PV Lakehouse Gold Layer
Server=localhost
Port=8081
Catalog=iceberg
Schema=gold
User=trino

// =============================================================================
// WINDOWS REGISTRY - For Manual Registration
// =============================================================================

// Path: HKEY_LOCAL_MACHINE\Software\ODBC\ODBC.INI\Trino_Lakehouse
// 
// Values:
// - Driver: Trino ODBC Driver (string)
// - Server: localhost (string)
// - Port: 8081 (dword)
// - Catalog: iceberg (string)
// - Schema: gold (string)
// - User: trino (string)

// =============================================================================
// POSTGRESQL DRIVER ALTERNATIVE (If Trino ODBC not available)
// =============================================================================

[Trino_Lakehouse_PG]
Driver=PostgreSQL Unicode
Server=localhost
Port=8081
Database=iceberg/gold
Username=trino
Password=

// Connection string:
// Driver={PostgreSQL Unicode};Server=localhost;Port=8081;Database=iceberg/gold;Username=trino

// =============================================================================
// CONNECTION TESTS
// =============================================================================

// Test 1: Basic connectivity
// SELECT 1 as test_connection;

// Test 2: Verify catalog access
// SELECT catalog_name FROM system.metadata.catalogs;

// Test 3: Verify schema access
// SELECT schema_name FROM information_schema.schemata WHERE catalog_name = 'iceberg';

// Test 4: Count records in fact table
// SELECT COUNT(*) as total_records FROM fact_solar_environmental;

// Test 5: Check dimensions
// SELECT COUNT(*) FROM dim_facility;
// SELECT COUNT(*) FROM dim_date;
// SELECT COUNT(*) FROM dim_time;
// SELECT COUNT(*) FROM dim_aqi_category;

// =============================================================================
// POWER BI DATA SOURCE CONFIGURATION
// =============================================================================

/**
 * Step 1: In Power BI Desktop
 *   - Click "Get Data"
 *   - Search for "ODBC"
 *   - Click "Connect"
 * 
 * Step 2: Select DSN
 *   - Choose "Trino_Lakehouse" from DSN list
 *   - OR paste connection string directly
 * 
 * Step 3: Authentication
 *   - User: trino
 *   - Password: (leave blank)
 * 
 * Step 4: Navigator
 *   - Select tables:
 *     * fact_solar_environmental (MAIN TABLE)
 *     * dim_facility
 *     * dim_date
 *     * dim_time
 *     * dim_aqi_category
 * 
 * Step 5: Data Transformation
 *   - Create relationships between tables
 *   - Set data types for columns
 *   - Create calculated measures
 * 
 * Step 6: Publish
 *   - Upload to Power BI Service
 *   - Configure refresh schedule
 */

// =============================================================================
// ADVANCED CONFIGURATION OPTIONS
// =============================================================================

// SSL/TLS Configuration (if enabled on server)
// SSLMode=require
// SSLCertificatePath=/path/to/certificate
// SSLKeyPath=/path/to/key

// Connection Pooling
// ConnectionPoolSize=10
// ConnectionTimeout=30

// Logging (for debugging)
// LogLevel=2
// LogPath=/var/log/trino-odbc.log

// Performance Tuning
// FetchSize=10000
// UseArrayFetch=1

// =============================================================================
// ENVIRONMENT VARIABLES (Linux/Mac)
// =============================================================================

// Set Trino server address
// export TRINO_SERVER=localhost:8081

// Set catalog and schema
// export TRINO_CATALOG=iceberg
// export TRINO_SCHEMA=gold

// Set user
// export TRINO_USER=trino

// =============================================================================
// DOCKER COMPOSE SERVICE DETAILS
// =============================================================================

/**
 * Service: trino
 * Image: trinodb/trino:latest
 * Container Port: 8080
 * Host Port: 8081 (mapped)
 * Status: Up and healthy
 * 
 * Access:
 * - Web UI: http://localhost:8081/ui/
 * - JDBC: jdbc:trino://localhost:8081
 * - ODBC: Driver={Trino ODBC Driver};Server=localhost;Port=8081
 */

// =============================================================================
// TROUBLESHOOTING CONNECTION ISSUES
// =============================================================================

/**
 * Error: "Driver not found"
 * Solution: Install Trino ODBC Driver from https://trino.io/download.html
 * 
 * Error: "Connection refused"
 * Solution: Check if Trino container is running
 *   docker ps | grep trino
 *   docker compose -f docker/docker-compose.yml restart trino
 * 
 * Error: "Authentication failed"
 * Solution: 
 *   - Leave password blank
 *   - Or use username: trino
 * 
 * Error: "Catalog/schema not found"
 * Solution: Verify catalog and schema names are correct
 *   - Catalog: iceberg
 *   - Schema: gold
 * 
 * Error: "Port already in use"
 * Solution: Change port mapping or kill process using port 8081
 *   lsof -i :8081  # Find process
 *   kill -9 <PID>   # Kill process
 */

// =============================================================================
// PERFORMANCE RECOMMENDATIONS
// =============================================================================

/**
 * For optimal Power BI performance:
 * 
 * 1. Import Strategy
 *    - Import dimension tables (small, <100KB each)
 *    - Import fact table or use DirectQuery based on size
 * 
 * 2. Query Optimization
 *    - Always filter by date range
 *    - Use is_valid = true
 *    - Pre-aggregate in Power BI queries
 * 
 * 3. Refresh Schedule
 *    - Daily refresh recommended
 *    - Off-peak hours (2-4 AM)
 *    - Incremental refresh for large datasets
 * 
 * 4. Connection Settings
 *    - Enable connection pooling
 *    - Set appropriate fetch size
 *    - Use compression if available
 */

// =============================================================================
// SAMPLE QUERIES FOR POWER BI
// =============================================================================

-- Load full fact table with dimensions
SELECT 
  f.facility_key,
  f.date_key,
  f.time_key,
  fac.facility_code,
  fac.facility_name,
  d.full_date,
  t.hour,
  f.energy_mwh,
  f.temperature_2m,
  f.shortwave_radiation,
  f.pm2_5,
  aqi.aqi_category
FROM iceberg.gold.fact_solar_environmental f
LEFT JOIN iceberg.gold.dim_facility fac ON f.facility_key = fac.facility_key
LEFT JOIN iceberg.gold.dim_date d ON f.date_key = d.date_key
LEFT JOIN iceberg.gold.dim_time t ON f.time_key = t.time_key
LEFT JOIN iceberg.gold.dim_aqi_category aqi ON f.aqi_category_key = aqi.aqi_category_key
WHERE f.is_valid = true
;

-- Load dimension tables separately (recommended for import)
SELECT * FROM iceberg.gold.dim_facility;
SELECT * FROM iceberg.gold.dim_date;
SELECT * FROM iceberg.gold.dim_time;
SELECT * FROM iceberg.gold.dim_aqi_category;

// =============================================================================
// INCREMENTAL REFRESH PATTERN
// =============================================================================

/**
 * For Power BI Service incremental refresh:
 * 
 * 1. Create calculated column with RangeStart/RangeEnd
 * 2. Set up parameters: 
 *    - RangeStart (earliest date)
 *    - RangeEnd (latest date)
 * 
 * 3. Query template:
 *    WHERE full_date >= @RangeStart AND full_date < @RangeEnd
 * 
 * 4. Configure refresh policy in Power BI Service:
 *    - Keep last 7 days of data
 *    - Increment by 1 day
 *    - Refresh on demand
 */

// =============================================================================
// Document Version: 1.0
// Last Updated: November 6, 2025
// Status: Production Ready
// =============================================================================
