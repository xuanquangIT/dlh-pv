# ML Hyperparameters Configuration
# Defines model settings and training parameters

# Model selection
model:
  type: "gbt"  # Options: "decision_tree", "gbt" - GBT is production default
  
# Decision Tree Regressor parameters (alternative)
decision_tree:
  max_depth: 20
  min_instances_per_node: 20
  max_bins: 64
  min_info_gain: 0.0
  seed: 42

# Gradient Boosted Trees parameters (PRODUCTION - matches original train_regression_model.py)
gbt:
  max_depth: 6  # Optimal depth for boosting
  max_iter: 120  # Slight increase for better convergence
  step_size: 0.1  # Conservative learning rate
  min_instances_per_node: 50
  max_bins: 128
  subsample_rate: 0.8  # Row sampling per iteration
  feature_subset_strategy: "auto"
  min_info_gain: 0.01
  seed: 42

# Training parameters
training:
  sample_limit: 50000  # Balance between performance and memory
  train_ratio: 0.7
  validation_ratio: 0.15
  test_ratio: 0.15
  random_seed: 42
  min_rows_required: 50  # Minimum rows for training (lowered for testing)

# Data split strategy
data_split:
  method: "random"  # Options: "random", "temporal"
  seed: 42

# Evaluation metrics to track
metrics:
  primary: "rmse"
  track:
    - "rmse"
    - "mae"
    - "r2"
    - "mse"

# MLflow experiment settings
mlflow:
  experiment_name: "pv_solar_regression"
  run_name_prefix: "regression_dt"
  artifact_path: "model"
  log_model: true
  log_artifacts: true

# Output table settings
output:
  gold_table: "lh.gold.fact_solar_forecast_regression"
  write_mode: "overwrite"
  enable_predictions_write: true
